{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "\n",
    "# silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/raw_analyst_ratings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'stock'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-06-05 10:30:54-04:00' '2020-06-03 10:45:20-04:00'\n",
      " '2020-05-26 04:30:07-04:00' ... '2017-12-06 07:04:31-04:00'\n",
      " '2017-11-15 06:04:52-04:00' '2017-11-14 13:25:57-04:00']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data['date'].unique())\n",
    "print(data['date'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Unnamed: 0  \\\n",
      "date                                    \n",
      "2020-06-05 10:30:54-04:00           0   \n",
      "2020-06-03 10:45:20-04:00           1   \n",
      "2020-05-26 04:30:07-04:00           2   \n",
      "2020-05-22 12:45:06-04:00           3   \n",
      "2020-05-22 11:38:59-04:00           4   \n",
      "\n",
      "                                                                    headline  \\\n",
      "date                                                                           \n",
      "2020-06-05 10:30:54-04:00            Stocks That Hit 52-Week Highs On Friday   \n",
      "2020-06-03 10:45:20-04:00         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2020-05-26 04:30:07-04:00                      71 Biggest Movers From Friday   \n",
      "2020-05-22 12:45:06-04:00       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "2020-05-22 11:38:59-04:00  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                                         url  \\\n",
      "date                                                                           \n",
      "2020-06-05 10:30:54-04:00  https://www.benzinga.com/news/20/06/16190091/s...   \n",
      "2020-06-03 10:45:20-04:00  https://www.benzinga.com/news/20/06/16170189/s...   \n",
      "2020-05-26 04:30:07-04:00  https://www.benzinga.com/news/20/05/16103463/7...   \n",
      "2020-05-22 12:45:06-04:00  https://www.benzinga.com/news/20/05/16095921/4...   \n",
      "2020-05-22 11:38:59-04:00  https://www.benzinga.com/news/20/05/16095304/b...   \n",
      "\n",
      "                                   publisher stock  \n",
      "date                                                \n",
      "2020-06-05 10:30:54-04:00  Benzinga Insights     A  \n",
      "2020-06-03 10:45:20-04:00  Benzinga Insights     A  \n",
      "2020-05-26 04:30:07-04:00         Lisa Levin     A  \n",
      "2020-05-22 12:45:06-04:00         Lisa Levin     A  \n",
      "2020-05-22 11:38:59-04:00         Vick Meyer     A  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime format in the news data\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Set 'date' as the index for the news DataFrame\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate dates found:\n",
      "<DatetimeArray>\n",
      "['2020-06-05 10:30:54-04:00', '2020-06-03 10:45:20-04:00',\n",
      " '2020-05-26 04:30:07-04:00', '2020-05-22 12:45:06-04:00',\n",
      " '2020-05-22 08:06:17-04:00',                       'NaT',\n",
      " '2020-06-09 10:52:15-04:00', '2020-06-08 10:32:42-04:00',\n",
      " '2020-06-05 07:40:08-04:00', '2020-06-04 14:46:13-04:00',\n",
      " ...\n",
      " '2017-08-22 11:12:05-04:00', '2016-02-09 08:54:09-04:00',\n",
      " '2020-05-21 08:34:23-04:00', '2020-05-15 10:33:10-04:00',\n",
      " '2019-09-29 15:18:32-04:00', '2019-06-27 10:21:33-04:00',\n",
      " '2019-05-14 11:32:34-04:00', '2019-05-13 11:33:32-04:00',\n",
      " '2018-09-18 11:39:11-04:00', '2018-01-05 11:47:36-04:00']\n",
      "Length: 4238, dtype: datetime64[ns, UTC-04:00]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime if it's not already\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "\n",
    "# Check for duplicate dates\n",
    "duplicates = data['date'].duplicated(keep=False)  # 'keep=False' marks all duplicates as True\n",
    "\n",
    "if duplicates.any():\n",
    "    print(\"Duplicate dates found:\")\n",
    "    print(data['date'][duplicates].unique())  # Print unique duplicate dates\n",
    "else:\n",
    "    print(\"No duplicate dates found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate dates, keeping the first occurrence\n",
    "data = data[~data.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                       date stock  \n",
      "0 2020-06-05 10:30:54-04:00     A  \n",
      "1 2020-06-03 10:45:20-04:00     A  \n",
      "2 2020-05-26 04:30:07-04:00     A  \n",
      "3 2020-05-22 12:45:06-04:00     A  \n",
      "4 2020-05-22 11:38:59-04:00     A  \n",
      "Columns in DataFrame: Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock'], dtype='object')\n",
      "Index is monotonic increasing: False\n",
      "Index is monotonic decreasing: False\n",
      "Duplicate dates found:\n",
      "DatetimeIndex(['2020-06-05 10:30:54-04:00', '2020-06-03 10:45:20-04:00',\n",
      "               '2020-05-26 04:30:07-04:00', '2020-05-22 12:45:06-04:00',\n",
      "               '2020-05-22 08:06:17-04:00',                       'NaT',\n",
      "               '2020-06-09 10:52:15-04:00', '2020-06-08 10:32:42-04:00',\n",
      "               '2020-06-05 07:40:08-04:00', '2020-06-04 14:46:13-04:00',\n",
      "               ...\n",
      "               '2017-08-22 11:12:05-04:00', '2016-02-09 08:54:09-04:00',\n",
      "               '2020-05-21 08:34:23-04:00', '2020-05-15 10:33:10-04:00',\n",
      "               '2019-09-29 15:18:32-04:00', '2019-06-27 10:21:33-04:00',\n",
      "               '2019-05-14 11:32:34-04:00', '2019-05-13 11:33:32-04:00',\n",
      "               '2018-09-18 11:39:11-04:00', '2018-01-05 11:47:36-04:00'],\n",
      "              dtype='datetime64[ns, UTC-04:00]', name='date', length=4238, freq=None)\n",
      "Unnamed: 0    0\n",
      "headline      0\n",
      "url           0\n",
      "publisher     0\n",
      "stock         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(\"Columns in DataFrame:\", data.columns)\n",
    "\n",
    "# Convert 'date' column to datetime format and set it as the index\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "# Check for monotonicity of the index\n",
    "is_monotonic_increasing = data.index.is_monotonic_increasing\n",
    "print(f\"Index is monotonic increasing: {is_monotonic_increasing}\")\n",
    "\n",
    "is_monotonic_decreasing = data.index.is_monotonic_decreasing\n",
    "print(f\"Index is monotonic decreasing: {is_monotonic_decreasing}\")\n",
    "\n",
    "# Check for and handle duplicate dates\n",
    "duplicates = data.index.duplicated(keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"Duplicate dates found:\")\n",
    "    print(data.index[duplicates].unique())\n",
    "    # Remove duplicates, keeping the first occurrence\n",
    "    data = data[~duplicates]\n",
    "else:\n",
    "    print(\"No duplicate dates found.\")\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is monotonic increasing: False\n",
      "Index is monotonic decreasing: False\n"
     ]
    }
   ],
   "source": [
    "# Check if the index is monotonic increasing\n",
    "is_monotonic = data.index.is_monotonic_increasing\n",
    "print(f\"Index is monotonic increasing: {is_monotonic}\")\n",
    "\n",
    "# Check if the index is monotonic decreasing\n",
    "is_monotonic = data.index.is_monotonic_decreasing\n",
    "print(f\"Index is monotonic decreasing: {is_monotonic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Sort the index of the news DataFrame\n",
    "data = data.sort_index()\n",
    "\n",
    "# Verify the index is now sorted\n",
    "print(data.index.is_monotonic_increasing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
